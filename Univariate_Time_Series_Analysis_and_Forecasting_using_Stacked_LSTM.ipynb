{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Univariate Time Series Analysis and Forecasting using Stacked LSTM",
      "provenance": [],
      "authorship_tag": "ABX9TyNYx8/0Aqv1H5DMEUPdXgCg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/swarnava-96/Time-Series/blob/main/Univariate_Time_Series_Analysis_and_Forecasting_using_Stacked_LSTM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_Koc5WWov_df"
      },
      "source": [
        "# **Univariate Time Series Analysis and Forecasting using Stacked LSTM**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmRuhghRzKl1",
        "outputId": "d0f3371f-5e0e-46b0-970e-ce7d8eeb3fad"
      },
      "source": [
        "!pip install tensorflow==2.5"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow==2.5\n",
            "  Downloading tensorflow-2.5.0-cp37-cp37m-manylinux2010_x86_64.whl (454.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 454.3 MB 15 kB/s \n",
            "\u001b[?25hRequirement already satisfied: wrapt~=1.12.1 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.12.1)\n",
            "Collecting grpcio~=1.34.0\n",
            "  Downloading grpcio-1.34.1-cp37-cp37m-manylinux2014_x86_64.whl (4.0 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.0 MB 42.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: gast==0.4.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.4.0)\n",
            "Requirement already satisfied: opt-einsum~=3.3.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.3.0)\n",
            "Requirement already satisfied: astunparse~=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.6.3)\n",
            "Requirement already satisfied: absl-py~=0.10 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.12.0)\n",
            "Requirement already satisfied: numpy~=1.19.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.19.5)\n",
            "Requirement already satisfied: protobuf>=3.9.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.17.3)\n",
            "Requirement already satisfied: flatbuffers~=1.12.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.12)\n",
            "Requirement already satisfied: termcolor~=1.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.0)\n",
            "Requirement already satisfied: six~=1.15.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.15.0)\n",
            "Requirement already satisfied: wheel~=0.35 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.37.0)\n",
            "Requirement already satisfied: keras-preprocessing~=1.1.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (1.1.2)\n",
            "Requirement already satisfied: tensorboard~=2.5 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (2.6.0)\n",
            "Requirement already satisfied: google-pasta~=0.2 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (0.2.0)\n",
            "Requirement already satisfied: h5py~=3.1.0 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.1.0)\n",
            "Requirement already satisfied: typing-extensions~=3.7.4 in /usr/local/lib/python3.7/dist-packages (from tensorflow==2.5) (3.7.4.3)\n",
            "Collecting tensorflow-estimator<2.6.0,>=2.5.0rc0\n",
            "  Downloading tensorflow_estimator-2.5.0-py2.py3-none-any.whl (462 kB)\n",
            "\u001b[K     |████████████████████████████████| 462 kB 55.9 MB/s \n",
            "\u001b[?25hCollecting keras-nightly~=2.5.0.dev\n",
            "  Downloading keras_nightly-2.5.0.dev2021032900-py2.py3-none-any.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 54.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: cached-property in /usr/local/lib/python3.7/dist-packages (from h5py~=3.1.0->tensorflow==2.5) (1.5.2)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.4.5)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (0.6.1)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (3.3.4)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.8.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.0.1)\n",
            "Requirement already satisfied: google-auth<2,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (1.34.0)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (57.4.0)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard~=2.5->tensorflow==2.5) (2.23.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.2.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (1.3.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (4.6.4)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<2,>=1.6.3->tensorboard~=2.5->tensorflow==2.5) (0.4.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2021.5.30)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.21.0->tensorboard~=2.5->tensorflow==2.5) (2.10)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard~=2.5->tensorflow==2.5) (3.1.1)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->markdown>=2.6.8->tensorboard~=2.5->tensorflow==2.5) (3.5.0)\n",
            "Installing collected packages: grpcio, tensorflow-estimator, keras-nightly, tensorflow\n",
            "  Attempting uninstall: grpcio\n",
            "    Found existing installation: grpcio 1.39.0\n",
            "    Uninstalling grpcio-1.39.0:\n",
            "      Successfully uninstalled grpcio-1.39.0\n",
            "  Attempting uninstall: tensorflow-estimator\n",
            "    Found existing installation: tensorflow-estimator 2.6.0\n",
            "    Uninstalling tensorflow-estimator-2.6.0:\n",
            "      Successfully uninstalled tensorflow-estimator-2.6.0\n",
            "  Attempting uninstall: tensorflow\n",
            "    Found existing installation: tensorflow 2.6.0\n",
            "    Uninstalling tensorflow-2.6.0:\n",
            "      Successfully uninstalled tensorflow-2.6.0\n",
            "Successfully installed grpcio-1.34.1 keras-nightly-2.5.0.dev2021032900 tensorflow-2.5.0 tensorflow-estimator-2.5.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GxvNBUgr0d_I"
      },
      "source": [
        "import tensorflow"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "6O9_pQnS0lTT",
        "outputId": "98731594-7c51-4afb-916b-0816e72f0770"
      },
      "source": [
        "tensorflow.__version__"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'2.5.0'"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lLybc91rwPGi"
      },
      "source": [
        "# Let importthe libraries\n",
        "\n",
        "import numpy as np\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import LSTM\n",
        "from tensorflow.keras.layers import Flatten"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O148mI4F9JTn"
      },
      "source": [
        "### Data Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AOwj2OH71SaS"
      },
      "source": [
        "# Preparing the independent and Dependent features\n",
        "\n",
        "def prepare_data(timeseries_data, n_features):\n",
        "  X, y = [], []\n",
        "  for i in range(len(timeseries_data)):\n",
        "    # Finding the end of this pattern\n",
        "    end_ix = i + n_features\n",
        "    # Checking if we are beyond the sequence\n",
        "    if end_ix > len(timeseries_data) - 1:\n",
        "      break\n",
        "    # Gather the input and output parts of the pattern\n",
        "    seq_X, seq_y = timeseries_data[i : end_ix], timeseries_data[end_ix]\n",
        "    X.append(seq_X)\n",
        "    y.append(seq_y)\n",
        "  return np.array(X), np.array(y)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dLsqSIwV3hdN"
      },
      "source": [
        "# Define input sequence\n",
        "timeseries_data = [110, 125, 133, 146, 158, 172, 187, 196, 210]\n",
        "\n",
        "# Choosing the number of time steps\n",
        "n_steps = 3\n",
        "\n",
        "# Split into samples\n",
        "X, y = prepare_data(timeseries_data, n_steps)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "neRkHcgQ4Mpd",
        "outputId": "f1f6ae03-f5c8-4d1a-e5bb-2b019e819325"
      },
      "source": [
        "# Lets see the X data and the y data\n",
        "print(X), print(y)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[110 125 133]\n",
            " [125 133 146]\n",
            " [133 146 158]\n",
            " [146 158 172]\n",
            " [158 172 187]\n",
            " [172 187 196]]\n",
            "[146 158 172 187 196 210]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, None)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V-XMh8ej4Ue3",
        "outputId": "71d7e6a6-8107-4d66-9603-17da1ddc474c"
      },
      "source": [
        "# Lets see the shape of X\n",
        "X.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuG3lThY4Y6w"
      },
      "source": [
        "# Reshape from [samples, timesteps] into [samples, timesteps, features]\n",
        "\n",
        "n_features = 1\n",
        "X = X.reshape((X.shape[0], X.shape[1], n_features))"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o5ysxWw99Os1"
      },
      "source": [
        "### Model Building"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DfWrCRYh4yJe",
        "outputId": "7408a495-e762-4e13-a8d9-fda00fb0ee68"
      },
      "source": [
        "# Building LSTM model\n",
        "\n",
        "## Defining the model\n",
        "model = Sequential()\n",
        "model.add(LSTM(50, activation = \"relu\", return_sequences = True, input_shape = (n_steps, n_features)))\n",
        "model.add(LSTM(50, activation = \"relu\"))\n",
        "model.add(Dense(1))\n",
        "model.compile(optimizer = \"adam\", loss = \"mse\")\n",
        "\n",
        "# Fitting the model\n",
        "model.fit(X, y, epochs = 300, verbose = 1)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/300\n",
            "1/1 [==============================] - 3s 3s/step - loss: 32884.4570\n",
            "Epoch 2/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 32323.8223\n",
            "Epoch 3/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 31791.1738\n",
            "Epoch 4/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 31251.4121\n",
            "Epoch 5/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 30662.9922\n",
            "Epoch 6/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 30060.8301\n",
            "Epoch 7/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 29535.7520\n",
            "Epoch 8/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 29187.4473\n",
            "Epoch 9/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 28874.4473\n",
            "Epoch 10/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 28559.0293\n",
            "Epoch 11/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 28233.4160\n",
            "Epoch 12/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 27898.4629\n",
            "Epoch 13/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 27554.5449\n",
            "Epoch 14/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 27196.7637\n",
            "Epoch 15/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 26816.1953\n",
            "Epoch 16/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 26400.8066\n",
            "Epoch 17/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 25934.8906\n",
            "Epoch 18/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 25396.7500\n",
            "Epoch 19/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 24765.4434\n",
            "Epoch 20/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 24027.4863\n",
            "Epoch 21/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 23177.9473\n",
            "Epoch 22/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 22231.0332\n",
            "Epoch 23/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 21212.1777\n",
            "Epoch 24/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 20168.0371\n",
            "Epoch 25/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 19159.8379\n",
            "Epoch 26/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 18192.9766\n",
            "Epoch 27/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17223.8145\n",
            "Epoch 28/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 16238.6641\n",
            "Epoch 29/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15191.2725\n",
            "Epoch 30/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 14011.4561\n",
            "Epoch 31/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 12603.8711\n",
            "Epoch 32/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 10903.3857\n",
            "Epoch 33/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 8960.5820\n",
            "Epoch 34/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7228.9082\n",
            "Epoch 35/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5667.8906\n",
            "Epoch 36/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4099.4316\n",
            "Epoch 37/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2697.2234\n",
            "Epoch 38/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1617.0792\n",
            "Epoch 39/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 741.5402\n",
            "Epoch 40/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 123.4539\n",
            "Epoch 41/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 111.0121\n",
            "Epoch 42/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 511.2440\n",
            "Epoch 43/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 642.8828\n",
            "Epoch 44/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 713.8337\n",
            "Epoch 45/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 607.8720\n",
            "Epoch 46/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 502.0704\n",
            "Epoch 47/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 424.0956\n",
            "Epoch 48/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 342.8213\n",
            "Epoch 49/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 254.6322\n",
            "Epoch 50/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 166.3158\n",
            "Epoch 51/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 90.4065\n",
            "Epoch 52/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 39.2906\n",
            "Epoch 53/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 17.8784\n",
            "Epoch 54/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 21.7877\n",
            "Epoch 55/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 39.6509\n",
            "Epoch 56/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 61.4799\n",
            "Epoch 57/300\n",
            "1/1 [==============================] - 0s 8ms/step - loss: 80.0433\n",
            "Epoch 58/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 90.7790\n",
            "Epoch 59/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 92.0093\n",
            "Epoch 60/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 84.6201\n",
            "Epoch 61/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 71.2473\n",
            "Epoch 62/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 55.3158\n",
            "Epoch 63/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 40.1542\n",
            "Epoch 64/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 28.3329\n",
            "Epoch 65/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 21.2874\n",
            "Epoch 66/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 19.2299\n",
            "Epoch 67/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 21.3136\n",
            "Epoch 68/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 25.9804\n",
            "Epoch 69/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 31.4067\n",
            "Epoch 70/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 35.9442\n",
            "Epoch 71/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 38.4580\n",
            "Epoch 72/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 38.4985\n",
            "Epoch 73/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 36.2830\n",
            "Epoch 74/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 32.5216\n",
            "Epoch 75/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 28.1620\n",
            "Epoch 76/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 24.1260\n",
            "Epoch 77/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 21.1044\n",
            "Epoch 78/300\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 19.4445\n",
            "Epoch 79/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 19.1355\n",
            "Epoch 80/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 19.8771\n",
            "Epoch 81/300\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 21.1986\n",
            "Epoch 82/300\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 22.5944\n",
            "Epoch 83/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 23.6421\n",
            "Epoch 84/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 24.0807\n",
            "Epoch 85/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 23.8394\n",
            "Epoch 86/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 23.0186\n",
            "Epoch 87/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 21.8365\n",
            "Epoch 88/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 20.5586\n",
            "Epoch 89/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 19.4275\n",
            "Epoch 90/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 18.6099\n",
            "Epoch 91/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 18.1702\n",
            "Epoch 92/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 18.0717\n",
            "Epoch 93/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 18.2147\n",
            "Epoch 94/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 18.5317\n",
            "Epoch 95/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 18.9843\n",
            "Epoch 96/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 18.9333\n",
            "Epoch 97/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 18.5390\n",
            "Epoch 98/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 18.0312\n",
            "Epoch 99/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.5018\n",
            "Epoch 100/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 17.0001\n",
            "Epoch 101/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 16.5545\n",
            "Epoch 102/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 16.1537\n",
            "Epoch 103/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 15.7369\n",
            "Epoch 104/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 15.1953\n",
            "Epoch 105/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 14.3970\n",
            "Epoch 106/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 13.3273\n",
            "Epoch 107/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 12.8228\n",
            "Epoch 108/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 12.5220\n",
            "Epoch 109/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 11.1274\n",
            "Epoch 110/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 10.6039\n",
            "Epoch 111/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 9.9910\n",
            "Epoch 112/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 8.7615\n",
            "Epoch 113/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 8.8386\n",
            "Epoch 114/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 7.2945\n",
            "Epoch 115/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 7.2749\n",
            "Epoch 116/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 6.3954\n",
            "Epoch 117/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.9357\n",
            "Epoch 118/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 5.4002\n",
            "Epoch 119/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 5.1563\n",
            "Epoch 120/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 4.8921\n",
            "Epoch 121/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 4.4997\n",
            "Epoch 122/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 4.4107\n",
            "Epoch 123/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 4.2440\n",
            "Epoch 124/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 4.1426\n",
            "Epoch 125/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.9663\n",
            "Epoch 126/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8823\n",
            "Epoch 127/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 3.8483\n",
            "Epoch 128/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.7459\n",
            "Epoch 129/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.7199\n",
            "Epoch 130/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.5921\n",
            "Epoch 131/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 3.6331\n",
            "Epoch 132/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5102\n",
            "Epoch 133/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.5591\n",
            "Epoch 134/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 3.4159\n",
            "Epoch 135/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.4808\n",
            "Epoch 136/300\n",
            "1/1 [==============================] - 0s 7ms/step - loss: 3.3556\n",
            "Epoch 137/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 3.4220\n",
            "Epoch 138/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2990\n",
            "Epoch 139/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.3457\n",
            "Epoch 140/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.2514\n",
            "Epoch 141/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.2771\n",
            "Epoch 142/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.2175\n",
            "Epoch 143/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1993\n",
            "Epoch 144/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.1805\n",
            "Epoch 145/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 3.1226\n",
            "Epoch 146/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.1326\n",
            "Epoch 147/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0645\n",
            "Epoch 148/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 3.0678\n",
            "Epoch 149/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 3.0282\n",
            "Epoch 150/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 2.9853\n",
            "Epoch 151/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.9858\n",
            "Epoch 152/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.9305\n",
            "Epoch 153/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.9021\n",
            "Epoch 154/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8927\n",
            "Epoch 155/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8423\n",
            "Epoch 156/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.8080\n",
            "Epoch 157/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7984\n",
            "Epoch 158/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.7637\n",
            "Epoch 159/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.7159\n",
            "Epoch 160/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.6925\n",
            "Epoch 161/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.6794\n",
            "Epoch 162/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6499\n",
            "Epoch 163/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.6096\n",
            "Epoch 164/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5709\n",
            "Epoch 165/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5416\n",
            "Epoch 166/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.5207\n",
            "Epoch 167/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.5073\n",
            "Epoch 168/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.5087\n",
            "Epoch 169/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.5375\n",
            "Epoch 170/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.6574\n",
            "Epoch 171/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.8204\n",
            "Epoch 172/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 3.0534\n",
            "Epoch 173/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.6526\n",
            "Epoch 174/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3285\n",
            "Epoch 175/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.4525\n",
            "Epoch 176/300\n",
            "1/1 [==============================] - 0s 20ms/step - loss: 2.6305\n",
            "Epoch 177/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5028\n",
            "Epoch 178/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 2.2534\n",
            "Epoch 179/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.3823\n",
            "Epoch 180/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.5276\n",
            "Epoch 181/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2905\n",
            "Epoch 182/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.2088\n",
            "Epoch 183/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.3636\n",
            "Epoch 184/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3104\n",
            "Epoch 185/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1604\n",
            "Epoch 186/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.1900\n",
            "Epoch 187/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.2601\n",
            "Epoch 188/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1874\n",
            "Epoch 189/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.1050\n",
            "Epoch 190/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.1577\n",
            "Epoch 191/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.1890\n",
            "Epoch 192/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 2.1038\n",
            "Epoch 193/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0700\n",
            "Epoch 194/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 2.1163\n",
            "Epoch 195/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.1096\n",
            "Epoch 196/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0509\n",
            "Epoch 197/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.0349\n",
            "Epoch 198/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.0630\n",
            "Epoch 199/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 2.0582\n",
            "Epoch 200/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.0139\n",
            "Epoch 201/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9985\n",
            "Epoch 202/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0149\n",
            "Epoch 203/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0113\n",
            "Epoch 204/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9810\n",
            "Epoch 205/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.9603\n",
            "Epoch 206/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9637\n",
            "Epoch 207/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9649\n",
            "Epoch 208/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.9478\n",
            "Epoch 209/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.9223\n",
            "Epoch 210/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9072\n",
            "Epoch 211/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.9031\n",
            "Epoch 212/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.8962\n",
            "Epoch 213/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8840\n",
            "Epoch 214/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8669\n",
            "Epoch 215/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8485\n",
            "Epoch 216/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.8284\n",
            "Epoch 217/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.8155\n",
            "Epoch 218/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8075\n",
            "Epoch 219/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.8167\n",
            "Epoch 220/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.8640\n",
            "Epoch 221/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.0690\n",
            "Epoch 222/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.7912\n",
            "Epoch 223/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 2.8655\n",
            "Epoch 224/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 2.2097\n",
            "Epoch 225/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7882\n",
            "Epoch 226/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 2.4253\n",
            "Epoch 227/300\n",
            "1/1 [==============================] - 0s 23ms/step - loss: 2.3880\n",
            "Epoch 228/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.7296\n",
            "Epoch 229/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 2.3188\n",
            "Epoch 230/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.2641\n",
            "Epoch 231/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.7339\n",
            "Epoch 232/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 2.3614\n",
            "Epoch 233/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.0298\n",
            "Epoch 234/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.8253\n",
            "Epoch 235/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 2.2660\n",
            "Epoch 236/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.7617\n",
            "Epoch 237/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9321\n",
            "Epoch 238/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.9456\n",
            "Epoch 239/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6747\n",
            "Epoch 240/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.9247\n",
            "Epoch 241/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6855\n",
            "Epoch 242/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.7664\n",
            "Epoch 243/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7909\n",
            "Epoch 244/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6250\n",
            "Epoch 245/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.8087\n",
            "Epoch 246/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6803\n",
            "Epoch 247/300\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.6313\n",
            "Epoch 248/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7463\n",
            "Epoch 249/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5887\n",
            "Epoch 250/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.6118\n",
            "Epoch 251/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6732\n",
            "Epoch 252/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.5716\n",
            "Epoch 253/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5303\n",
            "Epoch 254/300\n",
            "1/1 [==============================] - 0s 49ms/step - loss: 1.6100\n",
            "Epoch 255/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5573\n",
            "Epoch 256/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4600\n",
            "Epoch 257/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5376\n",
            "Epoch 258/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.7550\n",
            "Epoch 259/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5869\n",
            "Epoch 260/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.4170\n",
            "Epoch 261/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4459\n",
            "Epoch 262/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.5720\n",
            "Epoch 263/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.7077\n",
            "Epoch 264/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.4658\n",
            "Epoch 265/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3310\n",
            "Epoch 266/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3867\n",
            "Epoch 267/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.4691\n",
            "Epoch 268/300\n",
            "1/1 [==============================] - 0s 22ms/step - loss: 1.4959\n",
            "Epoch 269/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3461\n",
            "Epoch 270/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2694\n",
            "Epoch 271/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2949\n",
            "Epoch 272/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3584\n",
            "Epoch 273/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.4353\n",
            "Epoch 274/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.3642\n",
            "Epoch 275/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.2911\n",
            "Epoch 276/300\n",
            "1/1 [==============================] - 0s 15ms/step - loss: 1.2143\n",
            "Epoch 277/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.1963\n",
            "Epoch 278/300\n",
            "1/1 [==============================] - 0s 17ms/step - loss: 1.2290\n",
            "Epoch 279/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.3018\n",
            "Epoch 280/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.5173\n",
            "Epoch 281/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.5680\n",
            "Epoch 282/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6657\n",
            "Epoch 283/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.3095\n",
            "Epoch 284/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1268\n",
            "Epoch 285/300\n",
            "1/1 [==============================] - 0s 13ms/step - loss: 1.1419\n",
            "Epoch 286/300\n",
            "1/1 [==============================] - 0s 21ms/step - loss: 1.2956\n",
            "Epoch 287/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.6391\n",
            "Epoch 288/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.5003\n",
            "Epoch 289/300\n",
            "1/1 [==============================] - 0s 14ms/step - loss: 1.2438\n",
            "Epoch 290/300\n",
            "1/1 [==============================] - 0s 10ms/step - loss: 1.0596\n",
            "Epoch 291/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.2794\n",
            "Epoch 292/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.7312\n",
            "Epoch 293/300\n",
            "1/1 [==============================] - 0s 11ms/step - loss: 1.3462\n",
            "Epoch 294/300\n",
            "1/1 [==============================] - 0s 12ms/step - loss: 1.0596\n",
            "Epoch 295/300\n",
            "1/1 [==============================] - 0s 19ms/step - loss: 1.0582\n",
            "Epoch 296/300\n",
            "1/1 [==============================] - 0s 16ms/step - loss: 1.2028\n",
            "Epoch 297/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.2700\n",
            "Epoch 298/300\n",
            "1/1 [==============================] - 0s 18ms/step - loss: 1.0181\n",
            "Epoch 299/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 0.9456\n",
            "Epoch 300/300\n",
            "1/1 [==============================] - 0s 9ms/step - loss: 1.0365\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7faee879d990>"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JYI_qXv15ztm"
      },
      "source": [
        "### Predicting For the next 10 data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_Wp8_G8c5rRN",
        "outputId": "7466346c-e061-40ee-f5cf-1bab4df6b1e6"
      },
      "source": [
        "# Demostrating the data for the next 10 days\n",
        "\n",
        "x_input = np.array([187, 196, 210])\n",
        "temp_input = list(x_input)\n",
        "list_output = []\n",
        "i = 0\n",
        "\n",
        "while(i < 10):\n",
        "  if (len(temp_input) > 3):\n",
        "    x_input =np.array(temp_input[1:])\n",
        "    print(\"{} day input {}\".format(i, x_input))\n",
        "    x_input = x_input.reshape((1, n_steps, n_features))\n",
        "    yhat = model.predict(x_input, verbose = 0)\n",
        "    print(\"{} day output {}\".format(i, yhat))\n",
        "    temp_input.append(yhat[0][0])\n",
        "    temp_input = temp_input[1:]\n",
        "    list_output.append(yhat[0][0])\n",
        "    i = i + 1\n",
        "\n",
        "  else:\n",
        "    x_input = x_input.reshape((1, n_steps, n_features))\n",
        "    yhat = model.predict(x_input, verbose = 0)\n",
        "    print(yhat[0])\n",
        "    temp_input.append(yhat[0][0])\n",
        "    list_output.append(yhat[0][0])\n",
        "    i = i + 1\n",
        "\n",
        "print(list_output)\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[222.29054]\n",
            "1 day input [196.        210.        222.2905426]\n",
            "1 day output [[233.1637]]\n",
            "2 day input [210.         222.2905426  233.16369629]\n",
            "2 day output [[247.67923]]\n",
            "3 day input [222.29054 233.1637  247.67923]\n",
            "3 day output [[260.89413]]\n",
            "4 day input [233.1637  247.67923 260.89413]\n",
            "4 day output [[274.45288]]\n",
            "5 day input [247.67923 260.89413 274.45288]\n",
            "5 day output [[290.1584]]\n",
            "6 day input [260.89413 274.45288 290.1584 ]\n",
            "6 day output [[305.30588]]\n",
            "7 day input [274.45288 290.1584  305.30588]\n",
            "7 day output [[321.36472]]\n",
            "8 day input [290.1584  305.30588 321.36472]\n",
            "8 day output [[338.8331]]\n",
            "9 day input [305.30588 321.36472 338.8331 ]\n",
            "9 day output [[356.38583]]\n",
            "[222.29054, 233.1637, 247.67923, 260.89413, 274.45288, 290.1584, 305.30588, 321.36472, 338.8331, 356.38583]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d55gSBnu8eTf"
      },
      "source": [
        "### Visualizing the output"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 264
        },
        "id": "muOll8Sb8IAk",
        "outputId": "39fda0bb-8e1d-406c-9724-3577fcde65f1"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "day_new = np.arange(1, 10)\n",
        "day_pred = np.arange(10, 20)\n",
        "\n",
        "plt.plot(day_new, timeseries_data)\n",
        "plt.plot(day_pred, list_output);"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}